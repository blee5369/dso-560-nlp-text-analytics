{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "amber-scoop",
   "metadata": {},
   "source": [
    "# Homework 4 (Due Friday, Nov. 19th, 11:59pm PST)\n",
    "\n",
    "1. Identify **three pairs of documents** in the McDonalds review dataset that have over 0.85 cosine similarity using average token word2vec embeddings from spacy.\n",
    "\n",
    "Lets load dependencies, our data, and inspect it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "mysterious-deposit",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T04:27:55.541216Z",
     "start_time": "2021-11-15T04:27:54.164669Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "mcd = pd.read_csv('mcdonalds-yelp-negative-reviews.csv', encoding=\"ISO-8859-1\")\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "japanese-liver",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T05:47:31.467114Z",
     "start_time": "2021-11-14T05:47:31.452349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>city</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>679455653</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>I'm not a huge mcds lover, but I've been to be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>679455654</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Terrible customer service. I came in at 9:30pm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>679455655</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>First they \"lost\" my order, actually they gave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>679455656</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>I see I'm not the only one giving 1 star. Only...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>679455657</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Well, it's McDonald's, so you know what the fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id     city                                             review\n",
       "0  679455653  Atlanta  I'm not a huge mcds lover, but I've been to be...\n",
       "1  679455654  Atlanta  Terrible customer service. I came in at 9:30pm...\n",
       "2  679455655  Atlanta  First they \"lost\" my order, actually they gave...\n",
       "3  679455656  Atlanta  I see I'm not the only one giving 1 star. Only...\n",
       "4  679455657  Atlanta  Well, it's McDonald's, so you know what the fo..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-pitch",
   "metadata": {},
   "source": [
    "## Cleaning data \n",
    "\n",
    "While spacy handles tokenization, POS, stopword, and lemmatiziation steps of data cleaning we can still benefit from consolidating concepts using the logic below to map menu items and common themes back to single concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "combined-control",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T05:47:31.483165Z",
     "start_time": "2021-11-14T05:47:31.469117Z"
    }
   },
   "outputs": [],
   "source": [
    "def consolidate_concepts(text):\n",
    "    cleaned_reviews = []\n",
    "    for review in text['review']:\n",
    "        review = re.sub(r\"(?:mcdonald's?|mcdonalds?|macdonalds?|mcds?)\",'_MCDONALD_', review, flags=re.IGNORECASE)\n",
    "        review = re.sub(r\"(?:burgers?|cheeseburgers?|hamburgers?|hamburgersandwiches?)\",'_HAMBURGER_', review, flags=re.IGNORECASE)\n",
    "        review = re.sub(r\"(?:McNuggets?|nuggets?|nugs?)\",'_NUGGET_', review, flags=re.IGNORECASE)\n",
    "        review = re.sub(r\"(?:fries?|frys?|french fries?)\",'_FRIES_', review, flags=re.IGNORECASE)\n",
    "        cleaned_reviews.append(review)\n",
    "    \n",
    "    text['review_cleaned'] = cleaned_reviews\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "separate-generic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T05:47:31.594114Z",
     "start_time": "2021-11-14T05:47:31.486155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>city</th>\n",
       "      <th>review</th>\n",
       "      <th>review_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>679455653</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>I'm not a huge mcds lover, but I've been to be...</td>\n",
       "      <td>I'm not a huge _MCDONALD_ lover, but I've been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>679455654</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Terrible customer service. I came in at 9:30pm...</td>\n",
       "      <td>Terrible customer service. I came in at 9:30pm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>679455655</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>First they \"lost\" my order, actually they gave...</td>\n",
       "      <td>First they \"lost\" my order, actually they gave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>679455656</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>I see I'm not the only one giving 1 star. Only...</td>\n",
       "      <td>I see I'm not the only one giving 1 star. Only...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>679455657</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Well, it's McDonald's, so you know what the fo...</td>\n",
       "      <td>Well, it's _MCDONALD_, so you know what the fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id     city                                             review  \\\n",
       "0  679455653  Atlanta  I'm not a huge mcds lover, but I've been to be...   \n",
       "1  679455654  Atlanta  Terrible customer service. I came in at 9:30pm...   \n",
       "2  679455655  Atlanta  First they \"lost\" my order, actually they gave...   \n",
       "3  679455656  Atlanta  I see I'm not the only one giving 1 star. Only...   \n",
       "4  679455657  Atlanta  Well, it's McDonald's, so you know what the fo...   \n",
       "\n",
       "                                      review_cleaned  \n",
       "0  I'm not a huge _MCDONALD_ lover, but I've been...  \n",
       "1  Terrible customer service. I came in at 9:30pm...  \n",
       "2  First they \"lost\" my order, actually they gave...  \n",
       "3  I see I'm not the only one giving 1 star. Only...  \n",
       "4  Well, it's _MCDONALD_, so you know what the fo...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_mcd = consolidate_concepts(mcd)\n",
    "cleaned_mcd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-toner",
   "metadata": {},
   "source": [
    "## Run reviews through spaCy pipeline\n",
    "    \n",
    "Lets make the data simple for analysis by creating columns for each spacy NLP attribute we want.\n",
    "\n",
    "While running the pipeline lets compare similarity of document embeddings to each document that has already been processed, this means we will have pairwise comparisons bewteen all documents. we will write reviews with above .85 cos similarity out to be further analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fundamental-uzbekistan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T06:17:16.940182Z",
     "start_time": "2021-11-14T06:17:16.928666Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_spaCy_cols(text, similarity_df):\n",
    "    word_embeddings = []\n",
    "    ents = []\n",
    "    docs = []\n",
    "    for review in text['review']:\n",
    "        doc = nlp(review)\n",
    "        word_embeddings.append(doc.vector)\n",
    "        ents.append(doc.ents)\n",
    "        for count, vector in enumerate(doc):\n",
    "            if doc.similarity(vector) > .85:\n",
    "                similarity_df = similarity_df.append({'review_1':review, 'review_2':text.iloc[count, 2],\\\n",
    "                                                      'similarity':doc.similarity(vector)},ignore_index=True)\n",
    "        docs.append(doc)\n",
    "    text[\"doc_embeddings\"] = word_embeddings\n",
    "    text[\"entities\"] = ents\n",
    "\n",
    "        \n",
    "    return text, similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "addressed-deployment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T06:17:50.602636Z",
     "start_time": "2021-11-14T06:17:17.208943Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-1cefa10aa465>:10: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  if doc.similarity(vector) > .85:\n"
     ]
    }
   ],
   "source": [
    "similar_reviews = pd.DataFrame(columns = ['review_1', 'review_2', 'similarity'])\n",
    "\n",
    "mcd, similar_reviews = add_spaCy_cols(mcd, similar_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-imperial",
   "metadata": {},
   "source": [
    "## Lets get 3 random reviews that were over .85 similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "artistic-calculator",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T06:17:50.883756Z",
     "start_time": "2021-11-14T06:17:50.870057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Review 1-------------\n",
      "So my first experience with this McDonald's was the day that I moved in. I had a couple friends helping me. This McDonald's is directly across the street from my apartment.So, after witnessing a guy smash his van (we later were told by the po-po that it was stolen) into the light pole right at the c\n",
      "-----------Review 2-------------\n",
      "Worst McDonalds in the history of McDonalds. All of their employees are rude, serve cold food, and have bad attitudes.. Your better off with Taco Bell a mile away. Don't waste your time, or money.\n",
      "SIMILARITY:  0.85908\n",
      "\n",
      "-----------Review 1-------------\n",
      "OK. so. When we first moved here..... We had a bunch of friends visit and come stay at our brand new house back in 2008? I don't remember... a while back. But this joint was still fairly new. We came here on the way to the airport to drop off our weekend guests at the McCarran for a quick bite to ea\n",
      "-----------Review 2-------------\n",
      "We came here the day after Christmas with our 2 kids and our nephew to quickly eat breakfast. We were greeted in a very non friendly demeanor by this older woman who just couldn't get our order right. Once we got our order, she still got it wrong and I went back and said something to her. No apologi\n",
      "SIMILARITY:  0.86773\n",
      "\n",
      "-----------Review 1-------------\n",
      "This place is terrible. It's a 50/50 chance that they will get your order right. Maybe if they could hire people who spoke a word of English, they would get your orders right.I was JUST there. I wanted a coffee with no whip cream and extra caramel. Super easy, right? Apparently not. They put extra w\n",
      "-----------Review 2-------------\n",
      "I'm hooked on the McDonald's Oatmeal!When I want to grab some breakfast that's yummy, healthy, and easy to eat while I'm driving I head here. I'm always met with friendly service at the drive-through. They move pretty quickly and always get my order correct no matter how busy they are!\n",
      "SIMILARITY:  0.87589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, row in similar_reviews.sample(3).iterrows():\n",
    "    print(\"-----------Review 1-------------\", row['review_1'][:300], sep ='\\n')\n",
    "    print(\"-----------Review 2-------------\", row['review_2'][:300], sep ='\\n')\n",
    "    print(\"SIMILARITY: \", round(row['similarity'], 5))\n",
    "    print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-initial",
   "metadata": {},
   "source": [
    "# Using the `SMS_test` and `SMS_train` datasets, build a classification model \n",
    "\n",
    "(you can simply use the `sklearn.linear_model.LogisticRegression` model used. Please attempt at least two of the vectorization techniques below:\n",
    "* `CountVectorization`\n",
    "* `TfIdfVectorization`\n",
    "* `word2vec` spacy document-level vectors\n",
    "\n",
    "Make sure you perform the following:\n",
    "* use train/test split\n",
    "* use proper model evaluation metrics\n",
    "* text preprocessing (regex, stemming/lemmatization, stopword removal, grouping entities, etc.)\n",
    "\n",
    "A discussion of the following:\n",
    "* **What techniques** you tried to improve the performance of your model.\n",
    "* What you would try to do, given more time, that would improve the performance of your model.\n",
    "* Provide an example of two **error cases** - a false positive and a false negative - that your model got wrong, and why the model did not predict the correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "limiting-blind",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T20:20:21.556576Z",
     "start_time": "2021-11-14T20:20:21.512577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S. No.</th>\n",
       "      <th>Message_body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S. No.                                       Message_body     Label\n",
       "0       1                         Rofl. Its true to its name  Non-Spam\n",
       "1       2  The guy did some bitching but I acted like i'd...  Non-Spam\n",
       "2       3  Pity, * was in mood for that. So...any other s...  Non-Spam\n",
       "3       4               Will ü b going to esplanade fr home?  Non-Spam\n",
       "4       5  This is the 2nd time we have tried 2 contact u...      Spam"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_test = pd.read_csv('SMS_test.csv',  encoding=\"ISO-8859-1\")\n",
    "sms_train = pd.read_csv('SMS_train.csv',  encoding=\"ISO-8859-1\")\n",
    "sms_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "described-bahrain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T21:10:03.731511Z",
     "start_time": "2021-11-14T21:10:03.725512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our test data is ~12% of the total available data\n"
     ]
    }
   ],
   "source": [
    "print(f\"Our test data is ~{round((sms_test.shape[0] / (sms_train.shape[0]+sms_test.shape[0]))*100)}\\\n",
    "% of the total available data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "great-enlargement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T20:20:21.588609Z",
     "start_time": "2021-11-14T20:20:21.574578Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_unique_characters(regex, lines):\n",
    "    \"\"\"\n",
    "    Finds unique characters from a list of strings, almost certainly inefficiently \n",
    "    \n",
    "    \"\"\"\n",
    "    #Match anything that is non alpha-numeric or whitespace, creates list of lists of matching characters\n",
    "    potential_malforms = [re.findall(regex, review) for review in lines]\n",
    "\n",
    "    #lets whittle down this list of lists to a unqiue list, btw this took me way longer than it needed to\n",
    "    unique_malforms = set([char for review in potential_malforms for char in review])\n",
    "    \n",
    "    print(F\"Number of unique potential Malformed Characters: {len(unique_malforms)}, \\n\\nCandidates: {unique_malforms}\")\n",
    "    return unique_malforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "confident-discharge",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T20:20:21.620586Z",
     "start_time": "2021-11-14T20:20:21.606576Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_sms(df):\n",
    "    cleaned_message = []\n",
    "    for message in df['Message_body']:\n",
    "        cleaned_message.append(re.sub(r\"[^A-Za-z0-9 ]\",'',message))\n",
    "    \n",
    "    df['cleaned_messages'] = cleaned_message\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "compact-johnson",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T21:26:59.086515Z",
     "start_time": "2021-11-14T21:26:59.078475Z"
    }
   },
   "outputs": [],
   "source": [
    "sms_train = clean_sms(sms_train)\n",
    "sms_test = clean_sms(sms_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "powered-plane",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T21:26:59.835703Z",
     "start_time": "2021-11-14T21:26:59.831876Z"
    }
   },
   "outputs": [],
   "source": [
    "def sms_spaCy_cols(text):\n",
    "    word_embeddings = []\n",
    "    ents = []\n",
    "    ent_type = []\n",
    "    for review in text['Message_body']:\n",
    "        doc = nlp(review)\n",
    "        word_embeddings.append(doc.vector)\n",
    "        ents.append(doc.ents)\n",
    "        for token in doc:\n",
    "            ent_list = []\n",
    "            ent_list.append(token.ent_type_)      \n",
    "        ent_type.append(ent_list)\n",
    "    text[\"doc_embeddings\"] = word_embeddings\n",
    "    text[\"entities\"] = ents\n",
    "    text['entity_types'] = ent_type\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "induced-straight",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T21:27:06.186780Z",
     "start_time": "2021-11-14T21:27:00.161777Z"
    }
   },
   "outputs": [],
   "source": [
    "sms_train_spacy = sms_spaCy_cols(sms_train)\n",
    "sms_test_spacy = sms_spaCy_cols(sms_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "hungarian-radius",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T21:27:06.330464Z",
     "start_time": "2021-11-14T21:27:06.316593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"hows my favourite person today? r u workin hard? couldn\\'t sleep again last nite nearly rang u at 4.30\"]'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(sms_train_spacy[sms_train_spacy['S. No.']==953]['Message_body'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-policy",
   "metadata": {},
   "source": [
    "## Feature engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-projector",
   "metadata": {},
   "source": [
    "### One hot encoding entity types\n",
    " It may be a variable of interest to have entity types including in aiding the detection of spam, to this end we have created one hot encodings of the entity types mentioned in each sms message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "promising-bullet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T04:11:56.896731Z",
     "start_time": "2021-11-15T04:11:56.880698Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stole list one hot encoding code from: https://stackoverflow.com/questions/52189126\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "test_onehot = pd.DataFrame(mlb.fit_transform(sms_test_spacy['entity_types']),\n",
    "                   columns=mlb.classes_,\n",
    "                   index=sms_test_spacy['entity_types'].index)\n",
    "\n",
    "train_onehot = pd.DataFrame(mlb.fit_transform(sms_train_spacy['entity_types']),\n",
    "                   columns=mlb.classes_,\n",
    "                   index=sms_train_spacy['entity_types'].index)\n",
    "\n",
    "#fill columns that dont exist in test data set and fill with 0s \n",
    "test_onehot['GPE'] = 0 \n",
    "test_onehot['LAW'] = 0\n",
    "\n",
    "# drop junk column\n",
    "train_onehot.drop(columns =[''], inplace=True)\n",
    "test_onehot.drop(columns =[''], inplace=True)\n",
    "\n",
    "# join back to main dfs \n",
    "sms_train_spacy = train_onehot.join(sms_train_spacy)\n",
    "sms_test_spacy = test_onehot.join(sms_test_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "periodic-reggae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T04:11:57.569295Z",
     "start_time": "2021-11-15T04:11:57.530535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARDINAL</th>\n",
       "      <th>DATE</th>\n",
       "      <th>GPE</th>\n",
       "      <th>LAW</th>\n",
       "      <th>MONEY</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>TIME</th>\n",
       "      <th>S. No.</th>\n",
       "      <th>Message_body</th>\n",
       "      <th>Label</th>\n",
       "      <th>cleaned_messages</th>\n",
       "      <th>doc_embeddings</th>\n",
       "      <th>entities</th>\n",
       "      <th>entity_types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>Non-Spam</td>\n",
       "      <td>Rofl Its true to its name</td>\n",
       "      <td>[0.09184885, 0.14416684, -0.2082083, -0.357044...</td>\n",
       "      <td>()</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>Non-Spam</td>\n",
       "      <td>The guy did some bitching but I acted like id ...</td>\n",
       "      <td>[-0.06460267, 0.17402254, -0.21391848, -0.0767...</td>\n",
       "      <td>((next, week),)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>Non-Spam</td>\n",
       "      <td>Pity  was in mood for that Soany other suggest...</td>\n",
       "      <td>[-0.05494839, 0.19570266, -0.13729948, -0.1639...</td>\n",
       "      <td>()</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>Non-Spam</td>\n",
       "      <td>Will  b going to esplanade fr home</td>\n",
       "      <td>[0.082603335, 0.08576301, -0.27380592, -0.1264...</td>\n",
       "      <td>()</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>Spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[-0.14296803, 0.27839, -0.02023539, -0.0788021...</td>\n",
       "      <td>((2nd), (2), (£, 750, Pound), (2), (Only, 10p)...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>953</td>\n",
       "      <td>hows my favourite person today? r u workin har...</td>\n",
       "      <td>Non-Spam</td>\n",
       "      <td>hows my favourite person today r u workin hard...</td>\n",
       "      <td>[-0.07621735, 0.2518853, -0.15996766, -0.09141...</td>\n",
       "      <td>((today), (rang, u), (4.30))</td>\n",
       "      <td>[CARDINAL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>954</td>\n",
       "      <td>How much you got for cleaning</td>\n",
       "      <td>Non-Spam</td>\n",
       "      <td>How much you got for cleaning</td>\n",
       "      <td>[-0.19166715, 0.31868, -0.28999516, -0.1143298...</td>\n",
       "      <td>()</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>955</td>\n",
       "      <td>Sorry da. I gone mad so many pending works wha...</td>\n",
       "      <td>Non-Spam</td>\n",
       "      <td>Sorry da I gone mad so many pending works what...</td>\n",
       "      <td>[0.01588447, 0.05694315, -0.2272758, -0.262425...</td>\n",
       "      <td>()</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>956</td>\n",
       "      <td>Wat time ü finish?</td>\n",
       "      <td>Non-Spam</td>\n",
       "      <td>Wat time  finish</td>\n",
       "      <td>[-0.0678088, 0.165192, -0.058875404, -0.404218...</td>\n",
       "      <td>()</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>957</td>\n",
       "      <td>Just glad to be talking to you.</td>\n",
       "      <td>Non-Spam</td>\n",
       "      <td>Just glad to be talking to you</td>\n",
       "      <td>[0.01585, 0.19437625, -0.3536925, -0.004909746...</td>\n",
       "      <td>()</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>957 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CARDINAL  DATE  GPE  LAW  MONEY  ORG  PERSON  PRODUCT  TIME  S. No.  \\\n",
       "0           0     0    0    0      0    0       0        0     0       1   \n",
       "1           0     0    0    0      0    0       0        0     0       2   \n",
       "2           0     0    0    0      0    0       0        0     0       3   \n",
       "3           0     0    0    0      0    0       0        0     0       4   \n",
       "4           0     0    0    0      0    0       0        0     0       5   \n",
       "..        ...   ...  ...  ...    ...  ...     ...      ...   ...     ...   \n",
       "952         1     0    0    0      0    0       0        0     0     953   \n",
       "953         0     0    0    0      0    0       0        0     0     954   \n",
       "954         0     0    0    0      0    0       0        0     0     955   \n",
       "955         0     0    0    0      0    0       0        0     0     956   \n",
       "956         0     0    0    0      0    0       0        0     0     957   \n",
       "\n",
       "                                          Message_body     Label  \\\n",
       "0                           Rofl. Its true to its name  Non-Spam   \n",
       "1    The guy did some bitching but I acted like i'd...  Non-Spam   \n",
       "2    Pity, * was in mood for that. So...any other s...  Non-Spam   \n",
       "3                 Will ü b going to esplanade fr home?  Non-Spam   \n",
       "4    This is the 2nd time we have tried 2 contact u...      Spam   \n",
       "..                                                 ...       ...   \n",
       "952  hows my favourite person today? r u workin har...  Non-Spam   \n",
       "953                      How much you got for cleaning  Non-Spam   \n",
       "954  Sorry da. I gone mad so many pending works wha...  Non-Spam   \n",
       "955                                 Wat time ü finish?  Non-Spam   \n",
       "956                    Just glad to be talking to you.  Non-Spam   \n",
       "\n",
       "                                      cleaned_messages  \\\n",
       "0                            Rofl Its true to its name   \n",
       "1    The guy did some bitching but I acted like id ...   \n",
       "2    Pity  was in mood for that Soany other suggest...   \n",
       "3                   Will  b going to esplanade fr home   \n",
       "4    This is the 2nd time we have tried 2 contact u...   \n",
       "..                                                 ...   \n",
       "952  hows my favourite person today r u workin hard...   \n",
       "953                      How much you got for cleaning   \n",
       "954  Sorry da I gone mad so many pending works what...   \n",
       "955                                   Wat time  finish   \n",
       "956                     Just glad to be talking to you   \n",
       "\n",
       "                                        doc_embeddings  \\\n",
       "0    [0.09184885, 0.14416684, -0.2082083, -0.357044...   \n",
       "1    [-0.06460267, 0.17402254, -0.21391848, -0.0767...   \n",
       "2    [-0.05494839, 0.19570266, -0.13729948, -0.1639...   \n",
       "3    [0.082603335, 0.08576301, -0.27380592, -0.1264...   \n",
       "4    [-0.14296803, 0.27839, -0.02023539, -0.0788021...   \n",
       "..                                                 ...   \n",
       "952  [-0.07621735, 0.2518853, -0.15996766, -0.09141...   \n",
       "953  [-0.19166715, 0.31868, -0.28999516, -0.1143298...   \n",
       "954  [0.01588447, 0.05694315, -0.2272758, -0.262425...   \n",
       "955  [-0.0678088, 0.165192, -0.058875404, -0.404218...   \n",
       "956  [0.01585, 0.19437625, -0.3536925, -0.004909746...   \n",
       "\n",
       "                                              entities entity_types  \n",
       "0                                                   ()           []  \n",
       "1                                      ((next, week),)           []  \n",
       "2                                                   ()           []  \n",
       "3                                                   ()           []  \n",
       "4    ((2nd), (2), (£, 750, Pound), (2), (Only, 10p)...           []  \n",
       "..                                                 ...          ...  \n",
       "952                       ((today), (rang, u), (4.30))   [CARDINAL]  \n",
       "953                                                 ()           []  \n",
       "954                                                 ()           []  \n",
       "955                                                 ()           []  \n",
       "956                                                 ()           []  \n",
       "\n",
       "[957 rows x 16 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_train_spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "verified-oklahoma",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T04:32:28.256707Z",
     "start_time": "2021-11-15T04:32:28.249198Z"
    }
   },
   "outputs": [],
   "source": [
    "x = sms_train_spacy['doc_embeddings'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "attached-swift",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T04:32:44.786868Z",
     "start_time": "2021-11-15T04:32:44.758533Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.09184885, 0.14416684, -0.2082083, -0.357044...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.06460267, 0.17402254, -0.21391848, -0.0767...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.05494839, 0.19570266, -0.13729948, -0.1639...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.082603335, 0.08576301, -0.27380592, -0.1264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.14296803, 0.27839, -0.02023539, -0.0788021...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>[-0.07621735, 0.2518853, -0.15996766, -0.09141...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>[-0.19166715, 0.31868, -0.28999516, -0.1143298...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>[0.01588447, 0.05694315, -0.2272758, -0.262425...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>[-0.0678088, 0.165192, -0.058875404, -0.404218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>[0.01585, 0.19437625, -0.3536925, -0.004909746...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>957 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0    [0.09184885, 0.14416684, -0.2082083, -0.357044...\n",
       "1    [-0.06460267, 0.17402254, -0.21391848, -0.0767...\n",
       "2    [-0.05494839, 0.19570266, -0.13729948, -0.1639...\n",
       "3    [0.082603335, 0.08576301, -0.27380592, -0.1264...\n",
       "4    [-0.14296803, 0.27839, -0.02023539, -0.0788021...\n",
       "..                                                 ...\n",
       "952  [-0.07621735, 0.2518853, -0.15996766, -0.09141...\n",
       "953  [-0.19166715, 0.31868, -0.28999516, -0.1143298...\n",
       "954  [0.01588447, 0.05694315, -0.2272758, -0.262425...\n",
       "955  [-0.0678088, 0.165192, -0.058875404, -0.404218...\n",
       "956  [0.01585, 0.19437625, -0.3536925, -0.004909746...\n",
       "\n",
       "[957 rows x 1 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "elementary-cargo",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T04:34:34.171827Z",
     "start_time": "2021-11-15T04:34:34.142902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.091849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.144167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.208208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.357044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.185335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>-0.141610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>-0.105271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.032140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>-0.047698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.194029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0    0.091849\n",
       "1    0.144167\n",
       "2   -0.208208\n",
       "3   -0.357044\n",
       "4    0.185335\n",
       "..        ...\n",
       "295 -0.141610\n",
       "296 -0.105271\n",
       "297  0.032140\n",
       "298 -0.047698\n",
       "299  0.194029\n",
       "\n",
       "[300 rows x 1 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-interference",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
